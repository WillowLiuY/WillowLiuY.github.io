<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Liu "Willow" Yang - Personal Website</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <div class="header-content">
            <div class="name">Liu "Willow" Yang</div>
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="research.html">Research</a></li>
                    <li><a href="files/CV-EN-LY.pdf" target="_blank">CV</a></li>
                    <li><a href="project.html">Projects</a></li>
                    <li><a href="https://github.com/WillowLiuY" target="_blank">GitHub</a></li>
                    <li><a href="https://scholar.google.com/citations?user=jU01qgsAAAAJ&hl=en" target="_blank">Google Scholar</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section id="home">
            <h1>About Me</h1>
            <div class="content">
                <div class="photo">
                    <img src="images/photo-ly.jpeg" alt="Liu Yang">
                </div>
                <div class="text">
                    <p>Hello! I'm Willow, a computer vision (CV) researcher & engineer deeply passionate about the intersection of 3D CV, deep learning, and robotic systems.</p>
                    <p>I earned my PhD from Purdue University as a member of the Lab of Computer-Integrated Infrastructure Informatics (LCIII). My research focused on developing CV algorithms using in-flight vision sensors to enable robotic agents, such as unmanned ground vehicles (UGVs), to perceive the complex environments and make better decisions.</p>
                    <p>Currently, I'm working as the R&D lead at a Medicare tech startup based at University of Tennessee, Knoxville (UTK). Here, I develop 3D vision-based algorithms for AI-driven laparoscopic robots. These algorithms leverage multi-source pre-operative and intra-operative data to enhance spatial perception for surgeons and create patient-specific models during surgical operation.</p>
                    <p>Let's innovate together and shape the future of intelligent robotics! Feel free to connect with me on <a href="https://www.linkedin.com/in/willowy">LinkedIn</a>.</p>
</div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <p>&copy; 2024 Liu Yang</p>
    </footer>
</body>
</html>
